{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import viz_2d as viz\n",
    "import acd\n",
    "import dset\n",
    "\n",
    "# %%\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('/run/media/xiangyu/Data/Projects/XAI/BHEM')\n",
    "from model import Cnn, getClassifier\n",
    "from dataset import handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dataset.mnist.handwriting'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[5 0 4 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "mnist = handwriting('mnist_784', normalize=True)\n",
    "print(type(mnist), type(mnist.X), type(mnist.y), type(mnist.XCnn))\n",
    "print(mnist.y)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(mnist.XCnn[0].reshape(28, 28), cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,), (70000, 1, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.X.shape, mnist.y.shape, mnist.XCnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cnn()\n",
    "checkpoint = torch.load('../../MINST.pkl', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsample = torch.tensor(mnist.XCnn[0:1]).to(device)\n",
    "X_preds = model(Xsample)\n",
    "Xsample.shape, X_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = getClassifier(Cnn, device, f_params='../../MINST.pkl')\n",
    "# X_preds = cnn.predict_proba(Xsample)\n",
    "# Xsample.shape, X_preds.shape\n",
    "# X_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AcdExp:\n",
    "    def __init__(self, image = None, sweep_dim=1):\n",
    "       # image: tensor(1,1,28,28)\n",
    "       self.image = image\n",
    "       self.sweep_dim = sweep_dim\n",
    "\n",
    "    def get_diff_scores(self, im_torch, im_orig, label_num, model, preds, sweep_dim):\n",
    "        '''Computes different attribution scores\n",
    "        '''\n",
    "        scores = []\n",
    "\n",
    "        # cd\n",
    "        # method = 'cd'\n",
    "        # tiles = acd.tiling_2d.gen_tiles(im_orig, fill=0, method=method, sweep_dim=sweep_dim)\n",
    "        # scores_cd = acd.get_scores_2d(model, method=method, ims=tiles, \n",
    "        #                             im_torch=im_torch, model_type=model_type, device=device)\n",
    "        # scores.append(scores_cd)\n",
    "\n",
    "        for method in ['occlusion', 'build_up']: # 'build_up'\n",
    "            tiles_break = acd.tiling_2d.gen_tiles(im_orig, fill=0, method=method, sweep_dim=sweep_dim)\n",
    "            preds_break = acd.get_scores_2d(model, method=method, ims=tiles_break, \n",
    "                                                im_torch=im_torch, pred_ims=dset.pred_ims)\n",
    "            if method == 'occlusion':\n",
    "                preds_break += preds\n",
    "            scores.append(np.copy(preds_break))\n",
    "        \n",
    "        # get integrated gradients scores\n",
    "        scores.append(acd.ig_scores_2d(model, im_torch, num_classes=10, \n",
    "                                            im_size=28, sweep_dim=sweep_dim, ind=[label_num], device=device))\n",
    "        return scores\n",
    "\n",
    "    def get_explanation(self, model, label):\n",
    "        # model is cnn object\n",
    "        # self.image is (1,1,28,28) tensor\n",
    "        X_orig = self.image.view(self.image.shape[-2], self.image.shape[-1]).cpu().numpy()\n",
    "        # pred.size = (10,)\n",
    "        preds = model(self.image).flatten().cpu().detach().numpy()\n",
    "        scores = self.get_diff_scores(self.image, X_orig, label, model, preds, self.sweep_dim)\n",
    "        return scores\n",
    "\n",
    "            # # plot raw image\n",
    "            # num_rows = len(im_nums)\n",
    "            # num_cols = len(scores) + 1\n",
    "            # plt.subplot(num_rows, num_cols, 1 + x * num_cols)\n",
    "            # plt.imshow(im_orig, cmap='gray')\n",
    "            # plt.gca().xaxis.set_visible(False)\n",
    "            # plt.yticks([])\n",
    "            # if x == 0:\n",
    "            #     plt.title('Image', fontsize=16)\n",
    "\n",
    "\n",
    "            # # plot scores\n",
    "            # vmax = max([np.max(scores[i]) for i in range(len(scores))])\n",
    "            # vmin = min([np.min(scores[i]) for i in range(len(scores))])\n",
    "            # vabs = max(abs(vmax), abs(vmin))\n",
    "            # for i, tit in enumerate(['CD', 'Occlusion', 'Build-Up', 'IG']):\n",
    "            #     plt.subplot(num_rows, num_cols, 2 + i + x * num_cols)\n",
    "            #     if i == 0:\n",
    "            #         plt.ylabel('pred: ' + str(ind[0]) + '...', fontsize=15)\n",
    "            #     if x == 0:\n",
    "            #         plt.title(tit, fontsize=16)\n",
    "            #     p = viz.visualize_preds(scores[i], num=label_num, cbar=False) #axis_off=False,  vabs=vabs)\n",
    "            #     plt.xticks([])\n",
    "            #     plt.yticks([])\n",
    "            #     divider = make_axes_locatable(plt.gca())\n",
    "            #     cax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\n",
    "            #     plt.colorbar(p, cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.tensor(mnist.XCnn[0].reshape(-1, 1, 28, 28)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangyu/.conda/envs/PyTc/lib/python3.12/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/xiangyu/.conda/envs/PyTc/lib/python3.12/site-packages/acd/scores/score_funcs.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(model(input_vecs))[:, class_to_explain]\n"
     ]
    }
   ],
   "source": [
    "ACDexp = AcdExp(image, sweep_dim=1)\n",
    "scores = ACDexp.get_explanation(model, mnist.y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 10)\n"
     ]
    }
   ],
   "source": [
    "score = score.reshape(28,28,10)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.moveaxis(score, -1, 0)\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = []\n",
    "for j in np.linspace(1, 0, 100):\n",
    "    colors.append((30./255, 136./255, 229./255,j))\n",
    "for j in np.linspace(0, 1, 100):\n",
    "    colors.append((255./255, 13./255, 87./255,j))\n",
    "red_transparent_blue = LinearSegmentedColormap.from_list(\"red_transparent_blue\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAADC8AAAEaCAYAAACL/ZzBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUdElEQVR4nO3d7avfdR3H8d/Xc3bhPFvMELe5WCplqWtJaSMrarTQOzIsirphRqFQWEJEMcO6EUR3rCGBXdyoMS0juqB0QlFBF3bDzUK6ztEKYeZqbZ1zOtvZ2af/YO8P7Lz229kej9svPp/PdnM/nvsOrbU2AgAAAAAAAAAAAAAACLlo3A8AAAAAAAAAAAAAAADOb+IFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQNTkuB8AAAAAAADABe7IdL2ZWtl31vRcvXnwsb6z9vys3hydqTdPf6Hvvs331Jv5hb6zevz8s/Vmy5WLdx8AAAAAcEHz5QUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABRQ2utjfsRAAAAAAAAnKHen3yGoZwsnKrPmjg+33ff3n315s5d9WbfA13X7XhyWbn53rb672A0Go1Gz/2rnPzo0k3lZvuur/fd98s/1Js3Xtt11DM77yw3l10yUW7Wra43AAAAAAA9fHkBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACImhz3AwAAAAAAACgcOFRvvv2rrqNm791RblZ9+KH6oPVru+4bXbOxnMwefqTc3PDg813X3XXTinIzfdlU11n3PT1RbnZet6w+6P3bu+4bfeLt5eS3E2u6jpo90crN5nX1nw8AAAAAYLH48gIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAICoobXWxv0IAAAAAAAATmP+ZDl59ljfUZ/68dFy89XbLy03Ky/q+4npI4/X9+369Q/rgza/tOu+r1x1Q7n5zE/7/rJ2vnlNubn7dVNdZwEAAAAAXOh8eQEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgaWmtt3I8AAAAAAADgzOzeP7NoZ93xtYfr0d239B22dqrevOKD9ebYN/vu63Fkum+3d3+9ec+bzuwtAAAAAAAXCF9eAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAEDW01tq4HwEAAAAAAMBZcuBQvbny8nqz6wd9993/SL05+o16Mwx99wEAAAAAcE7y5QUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABRQ2utjfsRAAAAAAAALDF/+2fX7LrvLpSb6RP1z1UHPra+676Ji4auHQAAAAAAZ5cvLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFFDa62N+xEAAAAAAAAsMcfn+3a//0c5+cXaK8rNiYW+n7S2Xb2yawcAAAAAwNnlywsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACihtZaG/cjAAAAAAAAOE/96bl6s3dfPbl1e9d1t674b7nZ9OjJrrMOfnxD1w4AAAAAgJovLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgaWmtt3I8AAAAAAADgwjU3X/9c9YHv/LvrrD2vmq1Hyya7zlq4al25mfjf8fqgS1Z23QcAAAAAcD7z5QUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBqaK21cT8CAAAAAAAATuf4yb6ftFbs+3O5efTil3Sd9a6Jw/Xo8LF6s/WarvtGK5b17QAAAAAAliBfXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABA1tNbauB8BAAAAAAAAi2Jmrt689f6+s37393Ky6b4Hys3Bt8z03XfTy/p2AAAAAABLkC8vAAAAAAAAAAAAAAAAUeIFAAAAAAAAAAAAAAAgSrwAAAAAAAAAAAAAAABEiRcAAAAAAAAAAAAAAIAo8QIAAAAAAAAAAAAAABAlXgAAAAAAAAAAAAAAAKLECwAAAAAAAAAAAAAAQJR4AQAAAAAAAAAAAAAAiBIvAAAAAAAAAAAAAAAAUUNrrY37EQAAAAAAAHCu+ehjR8rN+147VW4mO/87sY1rJsrN1Ar/NxkAAAAAsDT5100AAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABRQ2utjfsRAAAAAAAAcFpP/rFvd/CFenPXF/vO+vS7y8ncPbeVm5Wf3N133+fe27cDAAAAAFiCfHkBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABA1OS4HwAAAAAAAMD5q7VWbv4zV2/Wbr2m78LrN/XtOjx087Zys+Evc+Xmtre9ehFeAwAAAACwtPnyAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAEDU57gcAAAAAAABwjpmZqzcvHOs66vG51eXmW8/MlpvWuq4b7X7DUI/uvqXrrNdcsbzc3Pjijvuu3dJ1HwAAAADA+cyXFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAEQNrbU27kcAAAAAAABwZhZO9f3kM/HUX8vN7skN5eaOz3+p674jX7633Jzq+Lnq4d/Mdt1348bl5WbVsqHrrC3r67MAAAAAAOjjywsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAEDU0Fpr434EAAAAAADAhWj6+Kmu3dSRo4t2509mLi43H/r+kXJz+/X1OaPRaLTn6dlys+3qFeXmnZtXdd13y8tXlpthGLrOAgAAAABg8fjyAgAAAAAAAAAAAAAAECVeAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgKihtdbG/QgAAAAAAIClZPbEqXKz6omn6oNufmXfhU/sqzc7tvadtf/ZevP80Xrzjtd3Xff89EK5uXxqoussAAAAAACWLl9eAAAAAAAAAAAAAAAAosQLAAAAAAAAAAAAAABAlHgBAAAAAAAAAAAAAACIEi8AAAAAAAAAAAAAAABR4gUAAAAAAAAAAAAAACBKvAAAAAAAAAAAAAAAAESJFwAAAAAAAAAAAAAAgCjxAgAAAAAAAAAAAAAAEDW01tq4HwEAAAAAALCUzC/UP69Mn6g3a2dn+i48Pl9ODq1+UddR607M1qPlk/Vm9cVd9wEAAAAAwGjkywsAAAAAAAAAAAAAAECYeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAEDU0Fpr434EAAAAAAAAAAAAAABw/vLlBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACixAsAAAAAAAAAAAAAAECUeAEAAAAAAAAAAAAAAIgSLwAAAAAAAAAAAAAAAFHiBQAAAAAAAAAAAAAAIEq8AAAAAAAAAAAAAAAARIkXAAAAAAAAAAAAAACAKPECAAAAAAAAAAAAAAAQJV4AAAAAAAAAAAAAAACi/g/m2DCsEMqgdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 4000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    # plt.imshow(-bhem_exp.image, cmap='gray', alpha=0.3)\n",
    "    plt.imshow(score[i], cmap=red_transparent_blue, vmin=-np.nanpercentile(score, 99.9),vmax=np.nanpercentile(score, 99.9))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_scores(im_torch, im_orig, label_num, model, preds, sweep_dim):\n",
    "    '''Computes different attribution scores\n",
    "    '''\n",
    "    scores = []\n",
    "\n",
    "    # cd\n",
    "    method = 'cd'\n",
    "    tiles = acd.tiling_2d.gen_tiles(im_orig, fill=0, method=method, sweep_dim=sweep_dim)\n",
    "    scores_cd = acd.get_scores_2d(model, method=method, ims=tiles, \n",
    "                                   im_torch=im_torch, model_type=model_type, device=device)\n",
    "    scores.append(scores_cd)\n",
    "    for method in ['occlusion', 'build_up']: # 'build_up'\n",
    "        tiles_break = acd.tiling_2d.gen_tiles(im_orig, fill=0, method=method, sweep_dim=sweep_dim)\n",
    "        preds_break = acd.get_scores_2d(model, method=method, ims=tiles_break, \n",
    "                                            im_torch=im_torch, pred_ims=dset.pred_ims)\n",
    "        if method == 'occlusion':\n",
    "            preds_break += preds\n",
    "        scores.append(np.copy(preds_break))\n",
    "    \n",
    "    # get integrated gradients scores\n",
    "    scores.append(acd.ig_scores_2d(model, im_torch, num_classes=10, \n",
    "                                           im_size=28, sweep_dim=sweep_dim, ind=[label_num], device=device))\n",
    "    return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
